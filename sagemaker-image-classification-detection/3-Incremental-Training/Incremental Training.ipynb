{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Incremental Training\n",
    "\n",
    "SageMaker three built-in algorithms currently support incremental training: Object Detection Algorithm, Image Classification Algorithm, and Semantic Segmentation Algorithm.\n",
    "\n",
    "Note that SageMaker object detection algorithm currently only support the re-training feature with the same network, which means the new training job must have the same base_network and num_classes as the previous training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::476271697919:role/app-sagemaker-execution-role\n",
      "CPU times: user 673 ms, sys: 84 ms, total: 757 ms\n",
      "Wall time: 923 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "print(role)\n",
    "sess = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 'beyoung-sagemaker' # custom bucket name.\n",
    "# bucket = sess.default_bucket()\n",
    "prefix = 'coco-object-detection-20200422'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "433757028032.dkr.ecr.us-west-2.amazonaws.com/object-detection:latest\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "training_image = get_image_uri(sess.boto_region_name, 'object-detection', repo_version=\"latest\")\n",
    "print (training_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset and Channel Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_channel = prefix + '/train'\n",
    "validation_channel = prefix + '/validation'\n",
    "train_annotation_channel = prefix + '/train_annotation'\n",
    "validation_annotation_channel = prefix + '/validation_annotation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_train_data = 's3://{}/{}'.format(bucket, train_channel)\n",
    "s3_validation_data = 's3://{}/{}'.format(bucket, validation_channel)\n",
    "s3_train_annotation = 's3://{}/{}'.format(bucket, train_annotation_channel)\n",
    "s3_validation_annotation = 's3://{}/{}'.format(bucket, validation_annotation_channel)\n",
    "s3_output_location = 's3://{}/{}/output'.format(bucket, prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Ground Truth new labeling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labeled: 25\n",
      "output_uri: s3://beyoung-sm-groundtruth/output/demo-workshop-20200417/manifests/output/output.manifest\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "labeling_job = 'demo-workshop-20200417'\n",
    "\n",
    "client = boto3.client('sagemaker')\n",
    "response = client.describe_labeling_job(\n",
    "    LabelingJobName=labeling_job\n",
    ")\n",
    "\n",
    "total_labeled = response['LabelCounters']['TotalLabeled']\n",
    "output_uri = response['LabelingJobOutput']['OutputDatasetS3Uri']\n",
    "\n",
    "print('labeled: {}\\noutput_uri: {}'.format(total_labeled, output_uri))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 12.7 KiB/12.7 KiB (248.3 KiB/s) with 1 file(s) remaining\r",
      "download: s3://beyoung-sm-groundtruth/output/demo-workshop-20200417/manifests/output/output.manifest to ./output.manifest\r\n"
     ]
    }
   ],
   "source": [
    "## Copy mainfest files\n",
    "fp_manifest = './output.manifest'\n",
    "!aws s3 cp {output_uri} {fp_manifest}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping the labeling classes to COCO dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://beyoung-sm-groundtruth/output/demo-workshop-20200417/annotation-tool/data.json'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LabelCategoryConfigS3Uri = response['LabelCategoryConfigS3Uri']\n",
    "LabelCategoryConfigS3Uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://beyoung-sm-groundtruth/output/demo-workshop-20200417/annotation-tool/data.json to ./gt_label_config.json\n",
      "{\"document-version\":\"2018-11-28\",\"labels\":[{\"label\":\"bear\"},{\"label\":\"dog\"},{\"label\":\"cat\"},{\"label\":\"bird\"}]}"
     ]
    }
   ],
   "source": [
    "fp_gt = './gt_label_config.json'\n",
    "\n",
    "!aws s3 cp {LabelCategoryConfigS3Uri} ./{fp_gt}\n",
    "!cat {fp_gt}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bear', 'dog', 'cat', 'bird']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "gt_class = []\n",
    "with open(fp_gt) as f:\n",
    "    js = json.load(f)\n",
    "    labels = js['labels']\n",
    "    for i in labels:\n",
    "        gt_class.append(i['label'])\n",
    "gt_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_categories = ['person', 'bicycle', 'car',  'motorbike', 'aeroplane', 'bus', 'train', 'truck', 'boat', \n",
    "                     'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog',\n",
    "                     'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag',\n",
    "                     'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat',\n",
    "                     'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',\n",
    "                     'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot',\n",
    "                     'hot dog', 'pizza', 'donut', 'cake', 'chair', 'sofa', 'pottedplant', 'bed', 'diningtable',\n",
    "                     'toilet', 'tvmonitor', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven',\n",
    "                     'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier',\n",
    "                     'toothbrush']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object_categories.index('dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_mapper_fn(cls_id):\n",
    "    return object_categories.index(gt_class[cls_id])\n",
    "\n",
    "get_mapper_fn(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"source-ref\":\"s3://beyoung-sm-groundtruth/raw_data/sm_workshop/bear-01.jpg\",\"demo-workshop-20200417\":{\"annotations\":[{\"class_id\":0,\"width\":1021,\"top\":132,\"height\":1301,\"left\":143},{\"class_id\":0,\"width\":520,\"top\":519,\"height\":909,\"left\":976}],\"image_size\":[{\"width\":1500,\"depth\":3,\"height\":1434}]},\"demo-workshop-20200417-metadata\":{\"job-name\":\"labeling-job/demo-workshop-20200417\",\"class-map\":{\"0\":\"bear\"},\"human-annotated\":\"yes\",\"objects\":[{\"confidence\":0.09},{\"confidence\":0.09}],\"creation-date\":\"2020-04-20T03:47:36.100370\",\"type\":\"groundtruth/object-detection\"}}\r\n",
      "{\"source-ref\":\"s3://beyoung-sm-groundtruth/raw_data/sm_workshop/bear-02.jpg\",\"demo-workshop-20200417\":{\"annotations\":[{\"class_id\":0,\"width\":540,\"top\":96,\"height\":370,\"left\":82}],\"image_size\":[{\"width\":693,\"depth\":3,\"height\":600}]},\"demo-workshop-20200417-metadata\":{\"job-name\":\"labeling-job/demo-workshop-20200417\",\"class-map\":{\"0\":\"bear\"},\"human-annotated\":\"yes\",\"objects\":[{\"confidence\":0.09}],\"creation-date\":\"2020-04-20T03:47:36.119132\",\"type\":\"groundtruth/object-detection\"}}\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 2 {fp_manifest}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"21\": \"bear\", \"16\": \"dog\", \"15\": \"cat\", \"14\": \"bird\"}'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transfer class map\n",
    "# \"class-map\":{\"0\":\"bear\",\"1\":\"dog\",\"2\":\"cat\",\"3\":\"bird\"}\n",
    "\n",
    "new_class_map = {}\n",
    "for cls_name in gt_class:\n",
    "    coco_cls_id = str(object_categories.index(cls_name))\n",
    "    new_class_map[coco_cls_id] = cls_name\n",
    "\n",
    "json.dumps(new_class_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping the manifest file\n",
    "fp_coco_manifest = './output_coco_class.manifest'\n",
    "labeling_job = 'demo-workshop-20200417'\n",
    "\n",
    "data = []\n",
    "with open(fp_manifest) as f:\n",
    "    for line in f:\n",
    "        js = json.loads(line)\n",
    "        annotations = js[labeling_job]['annotations']\n",
    "        for notation in annotations:\n",
    "            cls_id = notation['class_id']\n",
    "            notation['class_id'] = get_mapper_fn(cls_id)\n",
    "        metadata = js[labeling_job+'-metadata']\n",
    "        metadata['class-map'] = new_class_map\n",
    "        data.append(js)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"source-ref\": \"s3://beyoung-sm-groundtruth/raw_data/sm_workshop/bear-01.jpg\", \"demo-workshop-20200417\": {\"annotations\": [{\"class_id\": 21, \"width\": 1021, \"top\": 132, \"height\": 1301, \"left\": 143}, {\"class_id\": 21, \"width\": 520, \"top\": 519, \"height\": 909, \"left\": 976}], \"image_size\": [{\"width\": 1500, \"depth\": 3, \"height\": 1434}]}, \"demo-workshop-20200417-metadata\": {\"job-name\": \"labeling-job/demo-workshop-20200417\", \"class-map\": {\"21\": \"bear\", \"16\": \"dog\", \"15\": \"cat\", \"14\": \"bird\"}, \"human-annotated\": \"yes\", \"objects\": [{\"confidence\": 0.09}, {\"confidence\": 0.09}], \"creation-date\": \"2020-04-20T03:47:36.100370\", \"type\": \"groundtruth/object-detection\"}}'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.dumps(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_coco_manifest = './output_coco_class.manifest'\n",
    "\n",
    "with open(fp_coco_manifest, \"w\") as f:\n",
    "    for line in data:\n",
    "        print(json.dumps(line), file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"source-ref\": \"s3://beyoung-sm-groundtruth/raw_data/sm_workshop/dog-06.jpg\", \"demo-workshop-20200417\": {\"annotations\": [{\"class_id\": 16, \"width\": 541, \"top\": 53, \"height\": 335, \"left\": 362}, {\"class_id\": 16, \"width\": 216, \"top\": 38, \"height\": 335, \"left\": 148}], \"image_size\": [{\"width\": 910, \"depth\": 3, \"height\": 432}]}, \"demo-workshop-20200417-metadata\": {\"job-name\": \"labeling-job/demo-workshop-20200417\", \"class-map\": {\"21\": \"bear\", \"16\": \"dog\", \"15\": \"cat\", \"14\": \"bird\"}, \"human-annotated\": \"yes\", \"objects\": [{\"confidence\": 0.09}, {\"confidence\": 0.09}], \"creation-date\": \"2020-04-20T03:46:31.217570\", \"type\": \"groundtruth/object-detection\"}}\r\n",
      "{\"source-ref\": \"s3://beyoung-sm-groundtruth/raw_data/sm_workshop/dog-07.jpg\", \"demo-workshop-20200417\": {\"annotations\": [{\"class_id\": 16, \"width\": 602, \"top\": 358, \"height\": 687, \"left\": 499}], \"image_size\": [{\"width\": 1694, \"depth\": 3, \"height\": 1979}]}, \"demo-workshop-20200417-metadata\": {\"job-name\": \"labeling-job/demo-workshop-20200417\", \"class-map\": {\"21\": \"bear\", \"16\": \"dog\", \"15\": \"cat\", \"14\": \"bird\"}, \"human-annotated\": \"yes\", \"objects\": [{\"confidence\": 0.09}], \"creation-date\": \"2020-04-20T03:48:40.964270\", \"type\": \"groundtruth/object-detection\"}}\r\n"
     ]
    }
   ],
   "source": [
    "# make sure the file format is correct\n",
    "!tail -n 2 {fp_coco_manifest}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_coco_train_manifest = \"./coco_train.manifest\"\n",
    "fp_coco_validation_manifest = \"./coco_validation.manifest\"\n",
    "\n",
    "dataset_size = len(data)\n",
    "train_test_split_index = round(dataset_size*0.8)\n",
    "\n",
    "train_data = data[:train_test_split_index]\n",
    "validation_data = data[train_test_split_index:]\n",
    "\n",
    "num_training_samples = 0\n",
    "with open(fp_coco_train_manifest, 'w') as f:\n",
    "    for line in train_data:\n",
    "        print(json.dumps(line), file=f)\n",
    "        num_training_samples += 1\n",
    "    \n",
    "with open(fp_coco_validation_manifest, 'w') as f:\n",
    "    for line in validation_data:\n",
    "        print(json.dumps(line), file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"source-ref\": \"s3://beyoung-sm-groundtruth/raw_data/sm_workshop/dog-03.jpg\", \"demo-workshop-20200417\": {\"annotations\": [{\"class_id\": 16, \"width\": 1924, \"top\": 382, \"height\": 2526, \"left\": 1055}], \"image_size\": [{\"width\": 4042, \"depth\": 3, \"height\": 2921}]}, \"demo-workshop-20200417-metadata\": {\"job-name\": \"labeling-job/demo-workshop-20200417\", \"class-map\": {\"21\": \"bear\", \"16\": \"dog\", \"15\": \"cat\", \"14\": \"bird\"}, \"human-annotated\": \"yes\", \"objects\": [{\"confidence\": 0.09}], \"creation-date\": \"2020-04-20T03:42:12.992614\", \"type\": \"groundtruth/object-detection\"}}\r\n",
      "{\"source-ref\": \"s3://beyoung-sm-groundtruth/raw_data/sm_workshop/dog-04.jpg\", \"demo-workshop-20200417\": {\"annotations\": [{\"class_id\": 16, \"width\": 174, \"top\": 10, \"height\": 386, \"left\": 75}], \"image_size\": [{\"width\": 268, \"depth\": 3, \"height\": 400}]}, \"demo-workshop-20200417-metadata\": {\"job-name\": \"labeling-job/demo-workshop-20200417\", \"class-map\": {\"21\": \"bear\", \"16\": \"dog\", \"15\": \"cat\", \"14\": \"bird\"}, \"human-annotated\": \"yes\", \"objects\": [{\"confidence\": 0.09}], \"creation-date\": \"2020-04-20T03:44:23.173945\", \"type\": \"groundtruth/object-detection\"}}\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 2 {fp_coco_validation_manifest}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ./coco_train.manifest to s3://beyoung-sagemaker/train_manifest/coco_train.manifest\n",
      "upload: ./coco_validation.manifest to s3://beyoung-sagemaker/validation_manifest/coco_validation.manifest\n"
     ]
    }
   ],
   "source": [
    "### upload coco manifest file to s3\n",
    "train_manifest_channel = 'train_manifest'\n",
    "s3_train_manifest = 's3://{}/{}/{}'.format(bucket, train_manifest_channel, fp_coco_train_manifest[2:])\n",
    "\n",
    "validation_manifest_channel = 'validation_manifest'\n",
    "s3_validation_manifest = 's3://{}/{}/{}'.format(bucket, validation_manifest_channel, fp_coco_validation_manifest[2:])\n",
    "\n",
    "!aws s3 cp {fp_coco_train_manifest} {s3_train_manifest}\n",
    "!aws s3 cp {fp_coco_validation_manifest} {s3_validation_manifest}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "print(num_training_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Incremental Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://beyoung-sagemaker/coco-object-detection-20200422/output/object-detection-2020-04-22-09-25-36-709/output/model.tar.gz'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the output model from the previous job.\n",
    "\n",
    "job_name = 'object-detection-2020-04-22-09-25-36-709'\n",
    "jb_respone = client.describe_training_job(TrainingJobName=job_name)\n",
    "model_s3uri = jb_respone['ModelArtifacts']['S3ModelArtifacts']\n",
    "model_s3uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = sagemaker.session.s3_input(model_s3uri, input_mode='File', distribution='FullyReplicated', \n",
    "                             content_type='application/x-sagemaker-model', s3_data_type='S3Prefix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure manifest training\n",
    "\n",
    "Ground Truth output format is as the following:\n",
    "\n",
    "```\n",
    "{\"source-ref\": \"s3://bucket_name/path_to_a_dataset_object.jpeg\", \"labeling-job-name\": {\"annotations\":[{\"class_id\":\"0\",<bounding box dimensions>}],\"image_size\":[{<image size simensions>}]}\n",
    "```\n",
    "\n",
    "Be sure to pay close attention to the AttributeNames parameter in the training job request. The strings you specifuy in this field must correspond to those that are present in your augmented manifest.\n",
    "\n",
    "In this case, we would define *attribute_names = [\"source-ref\", \"labeling-job-name\"]*. And, the input_mode should be *Pipe*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a train data channel with S3_data_type as 'AugmentedManifestFile' and attribute names.\n",
    "manifest_attributes = [\"source-ref\", labeling_job]\n",
    "\n",
    "train_data = sagemaker.session.s3_input(s3_train_manifest,\n",
    "                                        input_mode='Pipe',\n",
    "                                        distribution='FullyReplicated',\n",
    "                                        content_type='application/x-recordio',\n",
    "                                        record_wrapping='RecordIO',\n",
    "                                        s3_data_type='AugmentedManifestFile',\n",
    "                                        attribute_names= manifest_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = sagemaker.session.s3_input(s3_validation_manifest,\n",
    "                                        input_mode='Pipe',\n",
    "                                        distribution='FullyReplicated',\n",
    "                                        content_type='application/x-recordio',\n",
    "                                        record_wrapping='RecordIO',\n",
    "                                        s3_data_type='AugmentedManifestFile',\n",
    "                                        attribute_names= manifest_attributes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important\n",
    "\n",
    "SageMaker did not allow train and validation in different modes. Both are 'Pipe' or 'File' modes. But you can not 'Pipe' and 'File' for train and validation channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation_data = sagemaker.session.s3_input(s3_validation_data, distribution='FullyReplicated', \n",
    "#                              content_type='image/jpeg', s3_data_type='S3Prefix', input_mode= 'File')\n",
    "# validation_annotation = sagemaker.session.s3_input(s3_validation_annotation, distribution='FullyReplicated', \n",
    "#                              content_type='image/jpeg', s3_data_type='S3Prefix', input_mode= 'File')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In addition to two data channels, add a 'model' channel for the training.\n",
    "new_data_channels = {'train': train_data, 'validation': validation_data, 'model': model_data}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here is the old model hyper parameters\n",
    "\n",
    "```\n",
    "od_model.set_hyperparameters(base_network='resnet-50',\n",
    "                             use_pretrained_model=1,\n",
    "                             num_classes=80,\n",
    "                             mini_batch_size=16,\n",
    "                             epochs=30,\n",
    "                             learning_rate=0.001,\n",
    "                             lr_scheduler_step='10',\n",
    "                             lr_scheduler_factor=0.1,\n",
    "                             optimizer='sgd',\n",
    "                             momentum=0.9,\n",
    "                             weight_decay=0.0005,\n",
    "                             overlap_threshold=0.5,\n",
    "                             nms_threshold=0.45,\n",
    "                             image_shape=512,\n",
    "                             label_width=600,\n",
    "                             num_training_samples=4452)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_od_model = sagemaker.estimator.Estimator(training_image,\n",
    "                                             role, \n",
    "                                             train_instance_count=1, \n",
    "                                             train_instance_type='ml.p3.2xlarge',\n",
    "                                             train_volume_size = 50,\n",
    "                                             train_max_run = 360000,\n",
    "                                             input_mode= 'Pipe',\n",
    "                                             output_path=s3_output_location,\n",
    "                                             sagemaker_session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because our training dataset is small (here is train:20, test:5)\n",
    "# if start from 32, it will get the error The number of input images must be bigger or equal to the mini_batch_size\n",
    "\n",
    "new_od_model.set_hyperparameters(base_network='resnet-50',\n",
    "                                 num_classes=80,\n",
    "                                 mini_batch_size=4,\n",
    "                                 epochs=10,\n",
    "                                 learning_rate=0.001,\n",
    "                                 optimizer='rmsprop',\n",
    "                                 momentum=0.9,\n",
    "                                 overlap_threshold=0.4,\n",
    "                                 nms_threshold=0.3,\n",
    "                                 image_shape=512,\n",
    "                                 label_width=600,\n",
    "                                 num_training_samples=num_training_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model fit to start Incremental Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_od_model.fit(inputs=new_data_channels, wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'object-detection-2020-04-23-11-00-11-319'"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_name = new_od_model.latest_training_job.job_name\n",
    "job_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "InProgress\n",
      "Completed\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "response = client.describe_training_job(TrainingJobName=job_name)\n",
    "status = response['TrainingJobStatus']\n",
    "\n",
    "while status == 'InProgress':\n",
    "    time.sleep(30)\n",
    "    response = client.describe_training_job(TrainingJobName=job_name)\n",
    "    status = response['TrainingJobStatus']\n",
    "    print(status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
