{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'yolov5'...\n",
      "remote: Enumerating objects: 17, done.\u001b[K\n",
      "remote: Counting objects: 100% (17/17), done.\u001b[K\n",
      "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
      "remote: Total 1811 (delta 6), reused 8 (delta 2), pack-reused 1794\u001b[K\n",
      "Receiving objects: 100% (1811/1811), 5.09 MiB | 41.37 MiB/s, done.\n",
      "Resolving deltas: 100% (1173/1173), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/ultralytics/yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/myAWSStudyBlog/yolov5-onnx-sm/2-onnx-neo/yolov5\n"
     ]
    }
   ],
   "source": [
    "%cd yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export PYTHONPATH=\"$PWD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from models.common import *\n",
    "from utils import google_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://drive.google.com/uc?export=download&id=1R5T6rIyy3lLwgFXNms8whc-387H0tMQO as ./yolov5s.pt... Done (2.3s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/serialization.py:657: SourceChangeWarning: source code of class 'models.yolo.Model' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/serialization.py:657: SourceChangeWarning: source code of class 'torch.nn.modules.conv.Conv2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "img = torch.zeros((1,3,640,640))  # image size(1,3,320,192) iDetection\n",
    "\n",
    "# Load PyTorch model\n",
    "google_utils.attempt_download('./yolov5s.pt')\n",
    "model = torch.load('./yolov5s.pt', map_location=torch.device('cpu'))['model'].float()\n",
    "model.eval()\n",
    "model.model[-1].export = False\n",
    "y = model(img)  # dry run\n",
    "\n",
    "torch.save(model, 'yolov5s-torch-modle.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\t    inference  requirements.txt  utils\r\n",
      "detect.py   LICENSE    test.py\t\t weights\r\n",
      "Dockerfile  models     train.py\t\t yolov5s.pt\r\n",
      "hubconf.py  README.md  tutorial.ipynb\t yolov5s-torch-modle.pth\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://beyoung-sm-yolo5/model/torch/yolov5s-torch-modle.tar.gz'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tarfile\n",
    "from sagemaker import s3\n",
    "\n",
    "with tarfile.open('yolov5s-torch-modle.tar.gz', mode='w:gz') as archive:\n",
    "    archive.add('yolov5s-torch-modle.pth')\n",
    "s3uri_model = s3.S3Uploader.upload('yolov5s-torch-modle.tar.gz', 's3://beyoung-sm-yolo5/model/torch')\n",
    "s3uri_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "model.0.conv.conv.weight \t torch.Size([32, 12, 3, 3])\n",
      "model.0.conv.bn.weight \t torch.Size([32])\n",
      "model.0.conv.bn.bias \t torch.Size([32])\n",
      "model.0.conv.bn.running_mean \t torch.Size([32])\n",
      "model.0.conv.bn.running_var \t torch.Size([32])\n",
      "model.0.conv.bn.num_batches_tracked \t torch.Size([])\n",
      "model.1.conv.weight \t torch.Size([64, 32, 3, 3])\n",
      "model.1.bn.weight \t torch.Size([64])\n",
      "model.1.bn.bias \t torch.Size([64])\n",
      "model.1.bn.running_mean \t torch.Size([64])\n",
      "model.1.bn.running_var \t torch.Size([64])\n",
      "model.1.bn.num_batches_tracked \t torch.Size([])\n",
      "model.2.cv1.conv.weight \t torch.Size([32, 64, 1, 1])\n",
      "model.2.cv1.bn.weight \t torch.Size([32])\n",
      "model.2.cv1.bn.bias \t torch.Size([32])\n",
      "model.2.cv1.bn.running_mean \t torch.Size([32])\n",
      "model.2.cv1.bn.running_var \t torch.Size([32])\n",
      "model.2.cv1.bn.num_batches_tracked \t torch.Size([])\n",
      "model.2.cv2.weight \t torch.Size([32, 64, 1, 1])\n",
      "model.2.cv3.weight \t torch.Size([32, 32, 1, 1])\n",
      "model.2.cv4.conv.weight \t torch.Size([64, 64, 1, 1])\n",
      "model.2.cv4.bn.weight \t torch.Size([64])\n",
      "model.2.cv4.bn.bias \t torch.Size([64])\n",
      "model.2.cv4.bn.running_mean \t torch.Size([64])\n",
      "model.2.cv4.bn.running_var \t torch.Size([64])\n",
      "model.2.cv4.bn.num_batches_tracked \t torch.Size([])\n",
      "model.2.bn.weight \t torch.Size([64])\n",
      "model.2.bn.bias \t torch.Size([64])\n",
      "model.2.bn.running_mean \t torch.Size([64])\n",
      "model.2.bn.running_var \t torch.Size([64])\n",
      "model.2.bn.num_batches_tracked \t torch.Size([])\n",
      "model.2.m.0.cv1.conv.weight \t torch.Size([32, 32, 1, 1])\n",
      "model.2.m.0.cv1.bn.weight \t torch.Size([32])\n",
      "model.2.m.0.cv1.bn.bias \t torch.Size([32])\n",
      "model.2.m.0.cv1.bn.running_mean \t torch.Size([32])\n",
      "model.2.m.0.cv1.bn.running_var \t torch.Size([32])\n",
      "model.2.m.0.cv1.bn.num_batches_tracked \t torch.Size([])\n",
      "model.2.m.0.cv2.conv.weight \t torch.Size([32, 32, 3, 3])\n",
      "model.2.m.0.cv2.bn.weight \t torch.Size([32])\n",
      "model.2.m.0.cv2.bn.bias \t torch.Size([32])\n",
      "model.2.m.0.cv2.bn.running_mean \t torch.Size([32])\n",
      "model.2.m.0.cv2.bn.running_var \t torch.Size([32])\n",
      "model.2.m.0.cv2.bn.num_batches_tracked \t torch.Size([])\n",
      "model.3.conv.weight \t torch.Size([128, 64, 3, 3])\n",
      "model.3.bn.weight \t torch.Size([128])\n",
      "model.3.bn.bias \t torch.Size([128])\n",
      "model.3.bn.running_mean \t torch.Size([128])\n",
      "model.3.bn.running_var \t torch.Size([128])\n",
      "model.3.bn.num_batches_tracked \t torch.Size([])\n",
      "model.4.cv1.conv.weight \t torch.Size([64, 128, 1, 1])\n",
      "model.4.cv1.bn.weight \t torch.Size([64])\n",
      "model.4.cv1.bn.bias \t torch.Size([64])\n",
      "model.4.cv1.bn.running_mean \t torch.Size([64])\n",
      "model.4.cv1.bn.running_var \t torch.Size([64])\n",
      "model.4.cv1.bn.num_batches_tracked \t torch.Size([])\n",
      "model.4.cv2.weight \t torch.Size([64, 128, 1, 1])\n",
      "model.4.cv3.weight \t torch.Size([64, 64, 1, 1])\n",
      "model.4.cv4.conv.weight \t torch.Size([128, 128, 1, 1])\n",
      "model.4.cv4.bn.weight \t torch.Size([128])\n",
      "model.4.cv4.bn.bias \t torch.Size([128])\n",
      "model.4.cv4.bn.running_mean \t torch.Size([128])\n",
      "model.4.cv4.bn.running_var \t torch.Size([128])\n",
      "model.4.cv4.bn.num_batches_tracked \t torch.Size([])\n",
      "model.4.bn.weight \t torch.Size([128])\n",
      "model.4.bn.bias \t torch.Size([128])\n",
      "model.4.bn.running_mean \t torch.Size([128])\n",
      "model.4.bn.running_var \t torch.Size([128])\n",
      "model.4.bn.num_batches_tracked \t torch.Size([])\n",
      "model.4.m.0.cv1.conv.weight \t torch.Size([64, 64, 1, 1])\n",
      "model.4.m.0.cv1.bn.weight \t torch.Size([64])\n",
      "model.4.m.0.cv1.bn.bias \t torch.Size([64])\n",
      "model.4.m.0.cv1.bn.running_mean \t torch.Size([64])\n",
      "model.4.m.0.cv1.bn.running_var \t torch.Size([64])\n",
      "model.4.m.0.cv1.bn.num_batches_tracked \t torch.Size([])\n",
      "model.4.m.0.cv2.conv.weight \t torch.Size([64, 64, 3, 3])\n",
      "model.4.m.0.cv2.bn.weight \t torch.Size([64])\n",
      "model.4.m.0.cv2.bn.bias \t torch.Size([64])\n",
      "model.4.m.0.cv2.bn.running_mean \t torch.Size([64])\n",
      "model.4.m.0.cv2.bn.running_var \t torch.Size([64])\n",
      "model.4.m.0.cv2.bn.num_batches_tracked \t torch.Size([])\n",
      "model.4.m.1.cv1.conv.weight \t torch.Size([64, 64, 1, 1])\n",
      "model.4.m.1.cv1.bn.weight \t torch.Size([64])\n",
      "model.4.m.1.cv1.bn.bias \t torch.Size([64])\n",
      "model.4.m.1.cv1.bn.running_mean \t torch.Size([64])\n",
      "model.4.m.1.cv1.bn.running_var \t torch.Size([64])\n",
      "model.4.m.1.cv1.bn.num_batches_tracked \t torch.Size([])\n",
      "model.4.m.1.cv2.conv.weight \t torch.Size([64, 64, 3, 3])\n",
      "model.4.m.1.cv2.bn.weight \t torch.Size([64])\n",
      "model.4.m.1.cv2.bn.bias \t torch.Size([64])\n",
      "model.4.m.1.cv2.bn.running_mean \t torch.Size([64])\n",
      "model.4.m.1.cv2.bn.running_var \t torch.Size([64])\n",
      "model.4.m.1.cv2.bn.num_batches_tracked \t torch.Size([])\n",
      "model.4.m.2.cv1.conv.weight \t torch.Size([64, 64, 1, 1])\n",
      "model.4.m.2.cv1.bn.weight \t torch.Size([64])\n",
      "model.4.m.2.cv1.bn.bias \t torch.Size([64])\n",
      "model.4.m.2.cv1.bn.running_mean \t torch.Size([64])\n",
      "model.4.m.2.cv1.bn.running_var \t torch.Size([64])\n",
      "model.4.m.2.cv1.bn.num_batches_tracked \t torch.Size([])\n",
      "model.4.m.2.cv2.conv.weight \t torch.Size([64, 64, 3, 3])\n",
      "model.4.m.2.cv2.bn.weight \t torch.Size([64])\n",
      "model.4.m.2.cv2.bn.bias \t torch.Size([64])\n",
      "model.4.m.2.cv2.bn.running_mean \t torch.Size([64])\n",
      "model.4.m.2.cv2.bn.running_var \t torch.Size([64])\n",
      "model.4.m.2.cv2.bn.num_batches_tracked \t torch.Size([])\n",
      "model.5.conv.weight \t torch.Size([256, 128, 3, 3])\n",
      "model.5.bn.weight \t torch.Size([256])\n",
      "model.5.bn.bias \t torch.Size([256])\n",
      "model.5.bn.running_mean \t torch.Size([256])\n",
      "model.5.bn.running_var \t torch.Size([256])\n",
      "model.5.bn.num_batches_tracked \t torch.Size([])\n",
      "model.6.cv1.conv.weight \t torch.Size([128, 256, 1, 1])\n",
      "model.6.cv1.bn.weight \t torch.Size([128])\n",
      "model.6.cv1.bn.bias \t torch.Size([128])\n",
      "model.6.cv1.bn.running_mean \t torch.Size([128])\n",
      "model.6.cv1.bn.running_var \t torch.Size([128])\n",
      "model.6.cv1.bn.num_batches_tracked \t torch.Size([])\n",
      "model.6.cv2.weight \t torch.Size([128, 256, 1, 1])\n",
      "model.6.cv3.weight \t torch.Size([128, 128, 1, 1])\n",
      "model.6.cv4.conv.weight \t torch.Size([256, 256, 1, 1])\n",
      "model.6.cv4.bn.weight \t torch.Size([256])\n",
      "model.6.cv4.bn.bias \t torch.Size([256])\n",
      "model.6.cv4.bn.running_mean \t torch.Size([256])\n",
      "model.6.cv4.bn.running_var \t torch.Size([256])\n",
      "model.6.cv4.bn.num_batches_tracked \t torch.Size([])\n",
      "model.6.bn.weight \t torch.Size([256])\n",
      "model.6.bn.bias \t torch.Size([256])\n",
      "model.6.bn.running_mean \t torch.Size([256])\n",
      "model.6.bn.running_var \t torch.Size([256])\n",
      "model.6.bn.num_batches_tracked \t torch.Size([])\n",
      "model.6.m.0.cv1.conv.weight \t torch.Size([128, 128, 1, 1])\n",
      "model.6.m.0.cv1.bn.weight \t torch.Size([128])\n",
      "model.6.m.0.cv1.bn.bias \t torch.Size([128])\n",
      "model.6.m.0.cv1.bn.running_mean \t torch.Size([128])\n",
      "model.6.m.0.cv1.bn.running_var \t torch.Size([128])\n",
      "model.6.m.0.cv1.bn.num_batches_tracked \t torch.Size([])\n",
      "model.6.m.0.cv2.conv.weight \t torch.Size([128, 128, 3, 3])\n",
      "model.6.m.0.cv2.bn.weight \t torch.Size([128])\n",
      "model.6.m.0.cv2.bn.bias \t torch.Size([128])\n",
      "model.6.m.0.cv2.bn.running_mean \t torch.Size([128])\n",
      "model.6.m.0.cv2.bn.running_var \t torch.Size([128])\n",
      "model.6.m.0.cv2.bn.num_batches_tracked \t torch.Size([])\n",
      "model.6.m.1.cv1.conv.weight \t torch.Size([128, 128, 1, 1])\n",
      "model.6.m.1.cv1.bn.weight \t torch.Size([128])\n",
      "model.6.m.1.cv1.bn.bias \t torch.Size([128])\n",
      "model.6.m.1.cv1.bn.running_mean \t torch.Size([128])\n",
      "model.6.m.1.cv1.bn.running_var \t torch.Size([128])\n",
      "model.6.m.1.cv1.bn.num_batches_tracked \t torch.Size([])\n",
      "model.6.m.1.cv2.conv.weight \t torch.Size([128, 128, 3, 3])\n",
      "model.6.m.1.cv2.bn.weight \t torch.Size([128])\n",
      "model.6.m.1.cv2.bn.bias \t torch.Size([128])\n",
      "model.6.m.1.cv2.bn.running_mean \t torch.Size([128])\n",
      "model.6.m.1.cv2.bn.running_var \t torch.Size([128])\n",
      "model.6.m.1.cv2.bn.num_batches_tracked \t torch.Size([])\n",
      "model.6.m.2.cv1.conv.weight \t torch.Size([128, 128, 1, 1])\n",
      "model.6.m.2.cv1.bn.weight \t torch.Size([128])\n",
      "model.6.m.2.cv1.bn.bias \t torch.Size([128])\n",
      "model.6.m.2.cv1.bn.running_mean \t torch.Size([128])\n",
      "model.6.m.2.cv1.bn.running_var \t torch.Size([128])\n",
      "model.6.m.2.cv1.bn.num_batches_tracked \t torch.Size([])\n",
      "model.6.m.2.cv2.conv.weight \t torch.Size([128, 128, 3, 3])\n",
      "model.6.m.2.cv2.bn.weight \t torch.Size([128])\n",
      "model.6.m.2.cv2.bn.bias \t torch.Size([128])\n",
      "model.6.m.2.cv2.bn.running_mean \t torch.Size([128])\n",
      "model.6.m.2.cv2.bn.running_var \t torch.Size([128])\n",
      "model.6.m.2.cv2.bn.num_batches_tracked \t torch.Size([])\n",
      "model.7.conv.weight \t torch.Size([512, 256, 3, 3])\n",
      "model.7.bn.weight \t torch.Size([512])\n",
      "model.7.bn.bias \t torch.Size([512])\n",
      "model.7.bn.running_mean \t torch.Size([512])\n",
      "model.7.bn.running_var \t torch.Size([512])\n",
      "model.7.bn.num_batches_tracked \t torch.Size([])\n",
      "model.8.cv1.conv.weight \t torch.Size([256, 512, 1, 1])\n",
      "model.8.cv1.bn.weight \t torch.Size([256])\n",
      "model.8.cv1.bn.bias \t torch.Size([256])\n",
      "model.8.cv1.bn.running_mean \t torch.Size([256])\n",
      "model.8.cv1.bn.running_var \t torch.Size([256])\n",
      "model.8.cv1.bn.num_batches_tracked \t torch.Size([])\n",
      "model.8.cv2.conv.weight \t torch.Size([512, 1024, 1, 1])\n",
      "model.8.cv2.bn.weight \t torch.Size([512])\n",
      "model.8.cv2.bn.bias \t torch.Size([512])\n",
      "model.8.cv2.bn.running_mean \t torch.Size([512])\n",
      "model.8.cv2.bn.running_var \t torch.Size([512])\n",
      "model.8.cv2.bn.num_batches_tracked \t torch.Size([])\n",
      "model.9.cv1.conv.weight \t torch.Size([256, 512, 1, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.9.cv1.bn.weight \t torch.Size([256])\n",
      "model.9.cv1.bn.bias \t torch.Size([256])\n",
      "model.9.cv1.bn.running_mean \t torch.Size([256])\n",
      "model.9.cv1.bn.running_var \t torch.Size([256])\n",
      "model.9.cv1.bn.num_batches_tracked \t torch.Size([])\n",
      "model.9.cv2.weight \t torch.Size([256, 512, 1, 1])\n",
      "model.9.cv3.weight \t torch.Size([256, 256, 1, 1])\n",
      "model.9.cv4.conv.weight \t torch.Size([512, 512, 1, 1])\n",
      "model.9.cv4.bn.weight \t torch.Size([512])\n",
      "model.9.cv4.bn.bias \t torch.Size([512])\n",
      "model.9.cv4.bn.running_mean \t torch.Size([512])\n",
      "model.9.cv4.bn.running_var \t torch.Size([512])\n",
      "model.9.cv4.bn.num_batches_tracked \t torch.Size([])\n",
      "model.9.bn.weight \t torch.Size([512])\n",
      "model.9.bn.bias \t torch.Size([512])\n",
      "model.9.bn.running_mean \t torch.Size([512])\n",
      "model.9.bn.running_var \t torch.Size([512])\n",
      "model.9.bn.num_batches_tracked \t torch.Size([])\n",
      "model.9.m.0.cv1.conv.weight \t torch.Size([256, 256, 1, 1])\n",
      "model.9.m.0.cv1.bn.weight \t torch.Size([256])\n",
      "model.9.m.0.cv1.bn.bias \t torch.Size([256])\n",
      "model.9.m.0.cv1.bn.running_mean \t torch.Size([256])\n",
      "model.9.m.0.cv1.bn.running_var \t torch.Size([256])\n",
      "model.9.m.0.cv1.bn.num_batches_tracked \t torch.Size([])\n",
      "model.9.m.0.cv2.conv.weight \t torch.Size([256, 256, 3, 3])\n",
      "model.9.m.0.cv2.bn.weight \t torch.Size([256])\n",
      "model.9.m.0.cv2.bn.bias \t torch.Size([256])\n",
      "model.9.m.0.cv2.bn.running_mean \t torch.Size([256])\n",
      "model.9.m.0.cv2.bn.running_var \t torch.Size([256])\n",
      "model.9.m.0.cv2.bn.num_batches_tracked \t torch.Size([])\n",
      "model.10.conv.weight \t torch.Size([256, 512, 1, 1])\n",
      "model.10.bn.weight \t torch.Size([256])\n",
      "model.10.bn.bias \t torch.Size([256])\n",
      "model.10.bn.running_mean \t torch.Size([256])\n",
      "model.10.bn.running_var \t torch.Size([256])\n",
      "model.10.bn.num_batches_tracked \t torch.Size([])\n",
      "model.13.cv1.conv.weight \t torch.Size([128, 512, 1, 1])\n",
      "model.13.cv1.bn.weight \t torch.Size([128])\n",
      "model.13.cv1.bn.bias \t torch.Size([128])\n",
      "model.13.cv1.bn.running_mean \t torch.Size([128])\n",
      "model.13.cv1.bn.running_var \t torch.Size([128])\n",
      "model.13.cv1.bn.num_batches_tracked \t torch.Size([])\n",
      "model.13.cv2.weight \t torch.Size([128, 512, 1, 1])\n",
      "model.13.cv3.weight \t torch.Size([128, 128, 1, 1])\n",
      "model.13.cv4.conv.weight \t torch.Size([256, 256, 1, 1])\n",
      "model.13.cv4.bn.weight \t torch.Size([256])\n",
      "model.13.cv4.bn.bias \t torch.Size([256])\n",
      "model.13.cv4.bn.running_mean \t torch.Size([256])\n",
      "model.13.cv4.bn.running_var \t torch.Size([256])\n",
      "model.13.cv4.bn.num_batches_tracked \t torch.Size([])\n",
      "model.13.bn.weight \t torch.Size([256])\n",
      "model.13.bn.bias \t torch.Size([256])\n",
      "model.13.bn.running_mean \t torch.Size([256])\n",
      "model.13.bn.running_var \t torch.Size([256])\n",
      "model.13.bn.num_batches_tracked \t torch.Size([])\n",
      "model.13.m.0.cv1.conv.weight \t torch.Size([128, 128, 1, 1])\n",
      "model.13.m.0.cv1.bn.weight \t torch.Size([128])\n",
      "model.13.m.0.cv1.bn.bias \t torch.Size([128])\n",
      "model.13.m.0.cv1.bn.running_mean \t torch.Size([128])\n",
      "model.13.m.0.cv1.bn.running_var \t torch.Size([128])\n",
      "model.13.m.0.cv1.bn.num_batches_tracked \t torch.Size([])\n",
      "model.13.m.0.cv2.conv.weight \t torch.Size([128, 128, 3, 3])\n",
      "model.13.m.0.cv2.bn.weight \t torch.Size([128])\n",
      "model.13.m.0.cv2.bn.bias \t torch.Size([128])\n",
      "model.13.m.0.cv2.bn.running_mean \t torch.Size([128])\n",
      "model.13.m.0.cv2.bn.running_var \t torch.Size([128])\n",
      "model.13.m.0.cv2.bn.num_batches_tracked \t torch.Size([])\n",
      "model.14.conv.weight \t torch.Size([128, 256, 1, 1])\n",
      "model.14.bn.weight \t torch.Size([128])\n",
      "model.14.bn.bias \t torch.Size([128])\n",
      "model.14.bn.running_mean \t torch.Size([128])\n",
      "model.14.bn.running_var \t torch.Size([128])\n",
      "model.14.bn.num_batches_tracked \t torch.Size([])\n",
      "model.17.cv1.conv.weight \t torch.Size([64, 256, 1, 1])\n",
      "model.17.cv1.bn.weight \t torch.Size([64])\n",
      "model.17.cv1.bn.bias \t torch.Size([64])\n",
      "model.17.cv1.bn.running_mean \t torch.Size([64])\n",
      "model.17.cv1.bn.running_var \t torch.Size([64])\n",
      "model.17.cv1.bn.num_batches_tracked \t torch.Size([])\n",
      "model.17.cv2.weight \t torch.Size([64, 256, 1, 1])\n",
      "model.17.cv3.weight \t torch.Size([64, 64, 1, 1])\n",
      "model.17.cv4.conv.weight \t torch.Size([128, 128, 1, 1])\n",
      "model.17.cv4.bn.weight \t torch.Size([128])\n",
      "model.17.cv4.bn.bias \t torch.Size([128])\n",
      "model.17.cv4.bn.running_mean \t torch.Size([128])\n",
      "model.17.cv4.bn.running_var \t torch.Size([128])\n",
      "model.17.cv4.bn.num_batches_tracked \t torch.Size([])\n",
      "model.17.bn.weight \t torch.Size([128])\n",
      "model.17.bn.bias \t torch.Size([128])\n",
      "model.17.bn.running_mean \t torch.Size([128])\n",
      "model.17.bn.running_var \t torch.Size([128])\n",
      "model.17.bn.num_batches_tracked \t torch.Size([])\n",
      "model.17.m.0.cv1.conv.weight \t torch.Size([64, 64, 1, 1])\n",
      "model.17.m.0.cv1.bn.weight \t torch.Size([64])\n",
      "model.17.m.0.cv1.bn.bias \t torch.Size([64])\n",
      "model.17.m.0.cv1.bn.running_mean \t torch.Size([64])\n",
      "model.17.m.0.cv1.bn.running_var \t torch.Size([64])\n",
      "model.17.m.0.cv1.bn.num_batches_tracked \t torch.Size([])\n",
      "model.17.m.0.cv2.conv.weight \t torch.Size([64, 64, 3, 3])\n",
      "model.17.m.0.cv2.bn.weight \t torch.Size([64])\n",
      "model.17.m.0.cv2.bn.bias \t torch.Size([64])\n",
      "model.17.m.0.cv2.bn.running_mean \t torch.Size([64])\n",
      "model.17.m.0.cv2.bn.running_var \t torch.Size([64])\n",
      "model.17.m.0.cv2.bn.num_batches_tracked \t torch.Size([])\n",
      "model.18.weight \t torch.Size([255, 128, 1, 1])\n",
      "model.18.bias \t torch.Size([255])\n",
      "model.19.conv.weight \t torch.Size([128, 128, 3, 3])\n",
      "model.19.bn.weight \t torch.Size([128])\n",
      "model.19.bn.bias \t torch.Size([128])\n",
      "model.19.bn.running_mean \t torch.Size([128])\n",
      "model.19.bn.running_var \t torch.Size([128])\n",
      "model.19.bn.num_batches_tracked \t torch.Size([])\n",
      "model.21.cv1.conv.weight \t torch.Size([128, 256, 1, 1])\n",
      "model.21.cv1.bn.weight \t torch.Size([128])\n",
      "model.21.cv1.bn.bias \t torch.Size([128])\n",
      "model.21.cv1.bn.running_mean \t torch.Size([128])\n",
      "model.21.cv1.bn.running_var \t torch.Size([128])\n",
      "model.21.cv1.bn.num_batches_tracked \t torch.Size([])\n",
      "model.21.cv2.weight \t torch.Size([128, 256, 1, 1])\n",
      "model.21.cv3.weight \t torch.Size([128, 128, 1, 1])\n",
      "model.21.cv4.conv.weight \t torch.Size([256, 256, 1, 1])\n",
      "model.21.cv4.bn.weight \t torch.Size([256])\n",
      "model.21.cv4.bn.bias \t torch.Size([256])\n",
      "model.21.cv4.bn.running_mean \t torch.Size([256])\n",
      "model.21.cv4.bn.running_var \t torch.Size([256])\n",
      "model.21.cv4.bn.num_batches_tracked \t torch.Size([])\n",
      "model.21.bn.weight \t torch.Size([256])\n",
      "model.21.bn.bias \t torch.Size([256])\n",
      "model.21.bn.running_mean \t torch.Size([256])\n",
      "model.21.bn.running_var \t torch.Size([256])\n",
      "model.21.bn.num_batches_tracked \t torch.Size([])\n",
      "model.21.m.0.cv1.conv.weight \t torch.Size([128, 128, 1, 1])\n",
      "model.21.m.0.cv1.bn.weight \t torch.Size([128])\n",
      "model.21.m.0.cv1.bn.bias \t torch.Size([128])\n",
      "model.21.m.0.cv1.bn.running_mean \t torch.Size([128])\n",
      "model.21.m.0.cv1.bn.running_var \t torch.Size([128])\n",
      "model.21.m.0.cv1.bn.num_batches_tracked \t torch.Size([])\n",
      "model.21.m.0.cv2.conv.weight \t torch.Size([128, 128, 3, 3])\n",
      "model.21.m.0.cv2.bn.weight \t torch.Size([128])\n",
      "model.21.m.0.cv2.bn.bias \t torch.Size([128])\n",
      "model.21.m.0.cv2.bn.running_mean \t torch.Size([128])\n",
      "model.21.m.0.cv2.bn.running_var \t torch.Size([128])\n",
      "model.21.m.0.cv2.bn.num_batches_tracked \t torch.Size([])\n",
      "model.22.weight \t torch.Size([255, 256, 1, 1])\n",
      "model.22.bias \t torch.Size([255])\n",
      "model.23.conv.weight \t torch.Size([256, 256, 3, 3])\n",
      "model.23.bn.weight \t torch.Size([256])\n",
      "model.23.bn.bias \t torch.Size([256])\n",
      "model.23.bn.running_mean \t torch.Size([256])\n",
      "model.23.bn.running_var \t torch.Size([256])\n",
      "model.23.bn.num_batches_tracked \t torch.Size([])\n",
      "model.25.cv1.conv.weight \t torch.Size([256, 512, 1, 1])\n",
      "model.25.cv1.bn.weight \t torch.Size([256])\n",
      "model.25.cv1.bn.bias \t torch.Size([256])\n",
      "model.25.cv1.bn.running_mean \t torch.Size([256])\n",
      "model.25.cv1.bn.running_var \t torch.Size([256])\n",
      "model.25.cv1.bn.num_batches_tracked \t torch.Size([])\n",
      "model.25.cv2.weight \t torch.Size([256, 512, 1, 1])\n",
      "model.25.cv3.weight \t torch.Size([256, 256, 1, 1])\n",
      "model.25.cv4.conv.weight \t torch.Size([512, 512, 1, 1])\n",
      "model.25.cv4.bn.weight \t torch.Size([512])\n",
      "model.25.cv4.bn.bias \t torch.Size([512])\n",
      "model.25.cv4.bn.running_mean \t torch.Size([512])\n",
      "model.25.cv4.bn.running_var \t torch.Size([512])\n",
      "model.25.cv4.bn.num_batches_tracked \t torch.Size([])\n",
      "model.25.bn.weight \t torch.Size([512])\n",
      "model.25.bn.bias \t torch.Size([512])\n",
      "model.25.bn.running_mean \t torch.Size([512])\n",
      "model.25.bn.running_var \t torch.Size([512])\n",
      "model.25.bn.num_batches_tracked \t torch.Size([])\n",
      "model.25.m.0.cv1.conv.weight \t torch.Size([256, 256, 1, 1])\n",
      "model.25.m.0.cv1.bn.weight \t torch.Size([256])\n",
      "model.25.m.0.cv1.bn.bias \t torch.Size([256])\n",
      "model.25.m.0.cv1.bn.running_mean \t torch.Size([256])\n",
      "model.25.m.0.cv1.bn.running_var \t torch.Size([256])\n",
      "model.25.m.0.cv1.bn.num_batches_tracked \t torch.Size([])\n",
      "model.25.m.0.cv2.conv.weight \t torch.Size([256, 256, 3, 3])\n",
      "model.25.m.0.cv2.bn.weight \t torch.Size([256])\n",
      "model.25.m.0.cv2.bn.bias \t torch.Size([256])\n",
      "model.25.m.0.cv2.bn.running_mean \t torch.Size([256])\n",
      "model.25.m.0.cv2.bn.running_var \t torch.Size([256])\n",
      "model.25.m.0.cv2.bn.num_batches_tracked \t torch.Size([])\n",
      "model.26.weight \t torch.Size([255, 512, 1, 1])\n",
      "model.26.bias \t torch.Size([255])\n",
      "model.27.anchors \t torch.Size([3, 3, 2])\n",
      "model.27.anchor_grid \t torch.Size([3, 1, 3, 1, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "# Print model's state_dict\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'yolov5s-torch-state.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://beyoung-sm-yolo5/model/torch/yolov5s-torch-state.tar.gz'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tarfile.open('yolov5s-torch-state.tar.gz', mode='w:gz') as archive:\n",
    "    archive.add('yolov5s-torch-state.pth')\n",
    "s3uri_model = s3.S3Uploader.upload('yolov5s-torch-state.tar.gz', 's3://beyoung-sm-yolo5/model/torch')\n",
    "s3uri_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_latest_p36",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
